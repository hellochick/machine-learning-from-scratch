# machine-learning-from-scratch
My practice over the fundamental of Machine Learning models and algorithms from scratch. These are just my notes ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€.

The codes and the contents are based on [Machine Learning | Andrew Ng](https://www.youtube.com/playlist?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN).

## Table of Contents
### Interactive version with Plotly

| Notebook link | Course link (Andrew Ng) | Further Reading :notebook_with_decorative_cover::closed_book::green_book::orange_book::notebook::books: |
| :---: | :---: | :---- |
| [Linear Regression](https://hellochick.github.io/notebooks/LinearRegression.html) | [Chapter 2](https://www.youtube.com/watch?v=kHwlB_j7Hkc&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=4&ab_channel=ArtificialIntelligence-AllinOne) & [Chatper 4](https://www.youtube.com/watch?v=Q4GNLhRtZNc&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=18&ab_channel=ArtificialIntelligence-AllinOne) |  |
| [Logistic Regression](https://hellochick.github.io/notebooks/LogisticRegression.html) | [Chapter 6](https://www.youtube.com/watch?v=-la3q9d7AKQ&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=32&ab_channel=ArtificialIntelligence-AllinOne) | * [Generalized Linear Model (GLM)](https://towardsdatascience.com/generalized-linear-models-9cbf848bb8ab) <br> * [Logit v.s. Logistic](https://www.geo.fu-berlin.de/en/v/soga/Basics-of-statistics/Logistic-Regression/The-Logit-Function/index.html) / [Logit - wiki](https://en.wikipedia.org/wiki/Logit) <br> * [Softmax v.s. Sigmoid](https://stats.stackexchange.com/questions/233658/softmax-vs-sigmoid-function-in-logistic-classifier) |
| [Naive Bayes Classifier]() |  -  | * [Bayes theorem](https://www.youtube.com/watch?v=HZGCoVF3YvM) <br> * [Intuitive Explanation](https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/) |
| [Maximum Likelihood]() |  -  | * [Maximum Likelihood](https://youtu.be/XepXtl9YKwc) <br> * [Maximum Likelihood for Normal Distribution](https://youtu.be/Dn6b9fCIUpM) <br> (MLE as Least Square?) |

### Note of important ML concepts
* Evaluation Mertrics (from [wiki](https://en.wikipedia.org/wiki/Precision_and_recall))
![image](https://user-images.githubusercontent.com/18046598/126877136-151d6d2f-40df-400b-aaa7-698727096f2b.png)

  - Precision v.s. Recall 
  
  Try to remember the above table and use some example to help,

  ![image](https://user-images.githubusercontent.com/18046598/127457887-32bb9190-0d72-4bb6-8cf8-ef33bd872c9b.png)
  
  ![image](https://user-images.githubusercontent.com/18046598/127458110-bacb4bc1-184c-4bab-b621-9340aaf8ff7b.png)
  
  Remember that precision and recall really helps when dealing with **imbalance data**.
  - [ROC v.s. AUC](https://www.youtube.com/watch?v=4jRBRDbJemM)
  - [Lecture 11.3 â€” Machine Learning System Design | Error Metrics For Skewed Classes (Andrew Ng)](https://www.youtube.com/watch?v=wGw6R8Abcu)
